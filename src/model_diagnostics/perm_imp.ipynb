{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a75342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import polars as pl\n",
    "\n",
    "from model_diagnostics._utils.array import (\n",
    "    is_pandas_df,\n",
    "    is_pandas_series,\n",
    "    is_pyarrow_table,\n",
    "    length_of_first_dimension,\n",
    "    safe_assign_column,\n",
    "    safe_index_rows,\n",
    ")\n",
    "from model_diagnostics.scoring import SquaredError\n",
    "\n",
    "\n",
    "def safe_copy(X):\n",
    "    if hasattr(X, \"copy\"):\n",
    "        # pandas\n",
    "        X = X.copy()\n",
    "    elif is_pyarrow_table(X) or isinstance(X, pl.DataFrame):\n",
    "        # Copy on Write\n",
    "        pass\n",
    "    else:\n",
    "        X = copy.deepcopy(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def safe_column_names(X):\n",
    "    \"\"\"If we have column names, return them. Otherwise, return indices.\"\"\"\n",
    "    if is_pyarrow_table(X):\n",
    "        return X.column_names\n",
    "    elif is_pandas_df(X):\n",
    "        return X.columns.to_list()\n",
    "    elif hasattr(X, \"columns\"):\n",
    "        # polars\n",
    "        return X.columns\n",
    "    else:\n",
    "        # numpy\n",
    "        return list(range(X.shape[1]))\n",
    "\n",
    "\n",
    "def safe_index_rows_1d(x, row_indices):\n",
    "    # safe_index_rows() does not work for pandas series\n",
    "    if is_pandas_series(x):\n",
    "        return x.iloc[row_indices]\n",
    "    return safe_index_rows(x, row_indices)\n",
    "\n",
    "\n",
    "def safe_select_column(X, index):\n",
    "    if hasattr(X, \"iloc\"):\n",
    "        # pandas\n",
    "        out = X.iloc[:, index]\n",
    "    elif is_pyarrow_table(X):\n",
    "        out = X.column(index)\n",
    "    elif hasattr(X, \"select\"):\n",
    "        # polars\n",
    "        all_columns = safe_column_names(X)\n",
    "        out = X.select(all_columns[index])\n",
    "    else:\n",
    "        # numpy\n",
    "        out = X[:, index]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def safe_shuffle_cols(X, columns, row_indices):\n",
    "    X = safe_copy(X)  # Important\n",
    "    if isinstance(columns, (str, int)):\n",
    "        columns = [columns]\n",
    "    all_columns = safe_column_names(X)\n",
    "\n",
    "    for v in columns:\n",
    "        column_index = all_columns.index(v) if isinstance(v, str) else v\n",
    "        x = safe_select_column(X, column_index)\n",
    "        x_shuffled = safe_index_rows_1d(x, row_indices)\n",
    "        X = safe_assign_column(X, values=x_shuffled, column_index=column_index)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def compute_permutation_importance(\n",
    "    predict_function: Callable,\n",
    "    X: npt.ArrayLike,\n",
    "    y: npt.ArrayLike,\n",
    "    features: Optional[Union[list, tuple, set, dict]] = None,\n",
    "    scoring_function: Callable = SquaredError(),\n",
    "    weights: Optional[npt.ArrayLike] = None,\n",
    "    n_repeats: Optional[int] = 5,\n",
    "    n_max: Optional[int] = 10_000,\n",
    "    method: Optional[str] = \"difference\",\n",
    "    smaller_is_better: Optional[bool] = True,\n",
    "    rng: Optional[Union[np.random.Generator, int]] = None,\n",
    "):\n",
    "    \"\"\"Compute permutation feature importance.\n",
    "\n",
    "    This function calculates permutation feature importance for features and/or\n",
    "    feature groups according to the idea in `[Breiman]` and `[Fisher]`.\n",
    "\n",
    "    For each feature (group), permutation importance measures how much the model\n",
    "    performance (score) gets worse when re-calculating the model predictions after\n",
    "    permuting the values of that feature (group). The idea is that if a feature\n",
    "    is important, then shuffling its rows before calculating predictions will lead\n",
    "    to a large drop in model performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    predict_function : callable\n",
    "        A callable to get predictions, i.e. `predict_function(X)`.\n",
    "    X : array-like of shape (n_obs, n_features)\n",
    "        The dataframe or array of features to be passed to the model predict function.\n",
    "    y : npt.ArrayLike\n",
    "        1D array of shape (n_observations,) containing the target values.\n",
    "    features: list, tuple, dict, default=None\n",
    "        Iterable of feature names/indices of features in `X`. The default None\n",
    "        will use all features in `X`. Can also be a dictionary with lists of feature\n",
    "        names/indices as values. The keys of the dictionary are used as feature group\n",
    "        names. Example: `{\"x1\": [\"x1\"], \"x2\": [\"x2\"], \"size\": [\"x1\", \"x2\"]}`.\n",
    "    scoring_function : callable, default=SquaredError()\n",
    "        A scoring function with signature roughly\n",
    "        `fun(y_obs, y_pred, weights) -> float`.\n",
    "    weights : array-like of shape (n_obs) or None, default=None\n",
    "        Case weights passed to the scoring_function.\n",
    "    n_repeats : int, default=5\n",
    "        Number of times to repeat the permutation for each feature group.\n",
    "    n_max : int or None, default=10_000\n",
    "        Maximum number of observations used. If the number of observations is greater\n",
    "        than `n_max`, a random subset of size `n_max` will be drawn from `X`, `y`, (and\n",
    "        `weights`). Pass None for no subsampling.\n",
    "    method : str, default=\"difference\"\n",
    "        Normalization method for the importance scores. The options are: \"difference\",\n",
    "        \"ratio\", and \"raw\" (no normalization).\n",
    "    smaller_is_better : bool, default=True\n",
    "        If True, smaller values of the scoring_function are better.\n",
    "        If False, the role of shuffled scores and base_score is reversed.\n",
    "    rng : np.random.Generator, int or None, default=None\n",
    "        The random number generator used for shuffling values and for subsampling\n",
    "        `n_max` rows. The input is internally wrapped by `np.random.default_rng(rng)`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : polars.DataFrame\n",
    "        A DataFrame with the following columns:\n",
    "\n",
    "        - `feature`: Feature name or feature group name.\n",
    "        - `importance`: Sample mean of the importance scores.\n",
    "        - `standard_deviation`: Sample standard deviation of the importance scores\n",
    "          (None if `n_repeats = 1`).\n",
    "        - `base_score`: Performance score before shuffling.\n",
    "        - `n_repeats`: Number of repetitions used to calculate the importance score.\n",
    "\n",
    "        The values are sorted in decreasing order of importance.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    `[Breiman]`\n",
    "\n",
    "    :   Breiman, L. (2001).\n",
    "        \"Random Forests\".\n",
    "        Machine Learning, 45(1), 5-32.\n",
    "        https://doi.org/10.1023/A:1010933404324\n",
    "\n",
    "    `[Fisher]`\n",
    "\n",
    "    :   Fisher, A. and Rudin, C. and Dominici F. (2019).\n",
    "        \"All Models Are Wrong, but Many Are Useful: Learning a Variable's Importance\n",
    "        by Studying an Entire Class of Prediction Models Simultaneously\".\n",
    "        Journal of Machine Learning Research, 20(177), 1-81.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> import polars as pl\n",
    "    >>> from sklearn.linear_model import LinearRegression\n",
    "    >>>\n",
    "    >>> # Create a synthetic dataset\n",
    "    >>> rng = np.random.default_rng(1)\n",
    "    >>> n = 1000\n",
    "    >>>\n",
    "    >>> X = pl.DataFrame(\n",
    "    ...     {\n",
    "    ...         \"area\": rng.uniform(30, 120, n),\n",
    "    ...         \"rooms\": rng.choice([2.5, 3.5, 4.5], n),\n",
    "    ...         \"age\": rng.uniform(0, 100, n),\n",
    "    ...     }\n",
    "    ... )\n",
    "    >>>\n",
    "    >>> y = X[\"area\"] + 20 * X[\"rooms\"] + rng.normal(0, 1, n)\n",
    "    >>>\n",
    "    >>> model = LinearRegression()\n",
    "    >>> model.fit(X, y)\n",
    "    >>>\n",
    "    >>> perm_importance = compute_permutation_importance(\n",
    "    ...     predict_function=model.predict,\n",
    "    ...     X=X,\n",
    "    ...     y=y,\n",
    "    ...     rng=1,\n",
    "    ... )\n",
    "    >>> perm_importance\n",
    "    shape: (3, 5)\n",
    "    ┌─────────┬─────────────┬────────────────────┬────────────┬───────────┐\n",
    "    │ feature ┆ importance  ┆ standard_deviation ┆ base_score ┆ n_repeats │\n",
    "    │ ---     ┆ ---         ┆ ---                ┆ ---        ┆ ---       │\n",
    "    │ str     ┆ f64         ┆ f64                ┆ f64        ┆ i32       │\n",
    "    ╞═════════╪═════════════╪════════════════════╪════════════╪═══════════╡\n",
    "    │ area    ┆ 1352.856052 ┆ 36.695011          ┆ 0.99184    ┆ 5         │\n",
    "    │ rooms   ┆ 515.038303  ┆ 19.899192          ┆ 0.99184    ┆ 5         │\n",
    "    │ age     ┆ 0.001373    ┆ 0.001787           ┆ 0.99184    ┆ 5         │\n",
    "    └─────────┴─────────────┴────────────────────┴────────────┴───────────┘\n",
    "    >>>\n",
    "    >>> # Using feature subsets\n",
    "    >>> perm_importance = compute_permutation_importance(\n",
    "    ...     predict_function=model.predict,\n",
    "    ...     X=X,\n",
    "    ...     y=y,\n",
    "    ...     features=[\"area\", \"age\"],\n",
    "    ...     rng=1,\n",
    "    ... )\n",
    "    >>>\n",
    "    >>> # Using feature groups\n",
    "    >>> perm_importance = compute_permutation_importance(\n",
    "    ...     predict_function=model.predict,\n",
    "    ...     X=X,\n",
    "    ...     y=y,\n",
    "    ...     features={\"size\": [\"area\", \"rooms\"], \"age\": \"age\"},\n",
    "    ...     rng=1,\n",
    "    ... )\n",
    "    \"\"\"\n",
    "    # Turn features into form {\"x1\": [\"x1\"], \"x2\": [\"x2\"], \"group\": [\"x1\", \"x2\"]}\n",
    "    # While looking verbose, it is the most flexible way to handle all cases\n",
    "    if features is None:\n",
    "        features = safe_column_names(X)\n",
    "    if not isinstance(features, dict):\n",
    "        features = {v: [v] for v in features}\n",
    "\n",
    "    # Usually, the data is too large and we need subsampling\n",
    "    n = length_of_first_dimension(X)\n",
    "    rng_ = np.random.default_rng(rng)  # we need it later for shuffling\n",
    "    if n_max is not None and n > n_max:\n",
    "        row_indices = rng_.choice(n, size=n_max, replace=False)\n",
    "        X = safe_index_rows(X, row_indices)\n",
    "        y = safe_index_rows(y, row_indices)\n",
    "        if weights is not None:\n",
    "            weights = safe_index_rows(weights, row_indices)\n",
    "        n = n_max\n",
    "    else:\n",
    "        X = safe_copy(X)\n",
    "\n",
    "    # Pre-shuffle score\n",
    "    base_score = scoring_function(y, predict_function(X), weights=weights)\n",
    "\n",
    "    # Stack X per repetition\n",
    "    if n_repeats > 1:\n",
    "        X = safe_index_rows(X, np.tile(np.arange(n), n_repeats))\n",
    "        if is_pandas_df(X):\n",
    "            # duplicated index not working with pandas < 2\n",
    "            X = X.reset_index(drop=True)\n",
    "\n",
    "    # Loop over feature groups\n",
    "    scores = []\n",
    "    feature_groups = features.keys()\n",
    "\n",
    "    for feature_group in feature_groups:\n",
    "        shuffle_indices = np.concatenate(\n",
    "            [rng_.permutation(n) for _ in range(n_repeats)]\n",
    "        )\n",
    "        X_shuffled = safe_shuffle_cols(X, features[feature_group], shuffle_indices)\n",
    "\n",
    "        # Note: np.split() also works on Series and DataFrames\n",
    "        predictions = predict_function(X_shuffled)\n",
    "        scores_per_repetition = [\n",
    "            scoring_function(y, pred, weights=weights)\n",
    "            for pred in np.split(predictions, n_repeats, axis=0)\n",
    "        ]\n",
    "        scores.append(pl.Series(scores_per_repetition))\n",
    "\n",
    "    # Remove base score\n",
    "    direction = 1 if smaller_is_better else -1\n",
    "\n",
    "    if method == \"difference\":\n",
    "        scores = [direction * (s - base_score) for s in scores]\n",
    "    elif method == \"ratio\":\n",
    "        scores = [(s / base_score) ** direction for s in scores]\n",
    "    elif method == \"raw\":\n",
    "        pass\n",
    "    else:\n",
    "        msg = f\"Unknown normalization method: {method}\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Aggregate over repetitions\n",
    "    importance = pl.Series([s.mean() for s in scores])\n",
    "    std = pl.Series([s.std() for s in scores]) if n_repeats > 1 else 0  # or None?\n",
    "\n",
    "    out = pl.DataFrame(\n",
    "        {\n",
    "            \"feature\": feature_groups,\n",
    "            \"importance\": importance,\n",
    "            \"standard_deviation\": std,\n",
    "            \"base_score\": base_score,\n",
    "            \"n_repeats\": n_repeats,\n",
    "        }\n",
    "    ).sort(\"importance\", descending=True)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c6214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>feature</th><th>importance</th><th>standard_deviation</th><th>base_score</th><th>n_repeats</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td></tr></thead><tbody><tr><td>&quot;area&quot;</td><td>1352.856052</td><td>36.695011</td><td>0.99184</td><td>5</td></tr><tr><td>&quot;rooms&quot;</td><td>515.038303</td><td>19.899192</td><td>0.99184</td><td>5</td></tr><tr><td>&quot;age&quot;</td><td>0.001373</td><td>0.001787</td><td>0.99184</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌─────────┬─────────────┬────────────────────┬────────────┬───────────┐\n",
       "│ feature ┆ importance  ┆ standard_deviation ┆ base_score ┆ n_repeats │\n",
       "│ ---     ┆ ---         ┆ ---                ┆ ---        ┆ ---       │\n",
       "│ str     ┆ f64         ┆ f64                ┆ f64        ┆ i32       │\n",
       "╞═════════╪═════════════╪════════════════════╪════════════╪═══════════╡\n",
       "│ area    ┆ 1352.856052 ┆ 36.695011          ┆ 0.99184    ┆ 5         │\n",
       "│ rooms   ┆ 515.038303  ┆ 19.899192          ┆ 0.99184    ┆ 5         │\n",
       "│ age     ┆ 0.001373    ┆ 0.001787           ┆ 0.99184    ┆ 5         │\n",
       "└─────────┴─────────────┴────────────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xai import compute_permutation_importance\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Create a synthetic dataset\n",
    "rng = np.random.default_rng(1)\n",
    "n = 1000\n",
    "\n",
    "X = pl.DataFrame(\n",
    "    {\n",
    "        \"area\": rng.uniform(30, 120, n),\n",
    "        \"rooms\": rng.choice([2.5, 3.5, 4.5], n),\n",
    "        \"age\": rng.uniform(0, 100, n),\n",
    "    }\n",
    ")\n",
    "\n",
    "y = X[\"area\"] + 20 * X[\"rooms\"] + rng.normal(0, 1, n)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "perm_importance = compute_permutation_importance(\n",
    "    predict_function=model.predict,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    # features=[\"area\", \"age\"],  # pick only some features\n",
    "    # features={\"size\": [\"area\", \"rooms\"], \"age\": \"age\"},  # with feature groups\n",
    "    rng=1,\n",
    ")\n",
    "perm_importance\n",
    "\n",
    "# feature\timportance\tstandard_deviation\tbase_score\tn_repeats\n",
    "#  \"area\"\t1352.856052\t         36.695011\t   0.99184\t        5\n",
    "# \"rooms\"\t 515.038303\t         19.899192\t   0.99184\t        5\n",
    "#   \"age\"\t   0.001373\t          0.001787\t   0.99184\t        5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2b771043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>feature</th><th>importance</th><th>standard_deviation</th><th>base_score</th><th>n_repeats</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td></tr></thead><tbody><tr><td>&quot;area&quot;</td><td>1352.856052</td><td>36.695011</td><td>0.99184</td><td>5</td></tr><tr><td>&quot;rooms&quot;</td><td>515.038303</td><td>19.899192</td><td>0.99184</td><td>5</td></tr><tr><td>&quot;age&quot;</td><td>0.001373</td><td>0.001787</td><td>0.99184</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌─────────┬─────────────┬────────────────────┬────────────┬───────────┐\n",
       "│ feature ┆ importance  ┆ standard_deviation ┆ base_score ┆ n_repeats │\n",
       "│ ---     ┆ ---         ┆ ---                ┆ ---        ┆ ---       │\n",
       "│ str     ┆ f64         ┆ f64                ┆ f64        ┆ i32       │\n",
       "╞═════════╪═════════════╪════════════════════╪════════════╪═══════════╡\n",
       "│ area    ┆ 1352.856052 ┆ 36.695011          ┆ 0.99184    ┆ 5         │\n",
       "│ rooms   ┆ 515.038303  ┆ 19.899192          ┆ 0.99184    ┆ 5         │\n",
       "│ age     ┆ 0.001373    ┆ 0.001787           ┆ 0.99184    ┆ 5         │\n",
       "└─────────┴─────────────┴────────────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_importance = compute_permutation_importance(\n",
    "    predict_function=model.predict,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    # features=[\"area\", \"age\"],  # pick only some features\n",
    "    # features={\"size\": [\"area\", \"rooms\"], \"age\": \"age\"},  # with feature groups\n",
    "    rng=1,\n",
    ")\n",
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b77e9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "da403c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mayer\\ai-tools-for-actuaries\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mayer\\ai-tools-for-actuaries\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mayer\\ai-tools-for-actuaries\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mayer\\ai-tools-for-actuaries\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'importances_mean': array([1.40150641e+03, 5.09541831e+02, 4.47835881e-03]),\n",
       " 'importances_std': array([0., 0., 0.]),\n",
       " 'importances': array([[1.40150641e+03],\n",
       "        [5.09541831e+02],\n",
       "        [4.47835881e-03]])}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that numpy's std uses ddof=0 by default, while polars uses ddof=1\n",
    "permutation_importance(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    random_state=1,\n",
    "    n_jobs=1,\n",
    "    n_repeats=1,\n",
    "    # max_samples=10000,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5eeb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c229f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
